# ADAM: other ETS models

@Hyndman2008b proposed five classes of ETS models, based on the types of their components:

1. ANN; AAN; AAdN; ANA; AAA; AAdA;
2. MNN; MAN; MAdN; MNA; MAA; MAdA;
3. MNM; MAM; MAdM;
4. MMN; MMdN; MMM; MMdM;
5. ANM; AAM; AAdM; MMA; MMdA; AMN; AMdN; AMA; AMdA; AMM; AMdM

The `ets()` model from `forecast` package supports only the Classes 1 - 4. The Class 5 models are not included in the function mainly because they have infinite variances, specifically on long horizons and when the data has low values. Indeed, when the level in one of these models becomes close to zero, there is an increased chance of breaking the model due to the appearance of negative values (think of ETS(A,A,M) model, which might have a negative trend, leading to negative values, which are then multiplied by the positive seasonal indices). That is why in practice these models should only be used, when the level of the series is high. Furthermore, some of the models from the Class 5 are very difficult to estimate and are very sensitive to the smoothing parameters values. All of this gives a rationale for restricting the pool of models to the 19 from classes 1 - 4.

@Hyndman2008b demonstrate that models from the class 2 have closed forms of conditional expectation and variance, with the former corresponding to the point forecasts. However, the conditional distribution from these models is not Gaussian, so there are no formulae for the prediction intervals from these models. Yes, in some cases Normal distribution might be a fine approximation for the real one, but in general simulations should be preferred.

Class 3 models suffer from similar issues, but the situation worsens: there are no analytical solutions for the conditional mean and variance, and there are only approximations to these statistics.

Class 4 models have been discussed in [the previous section](#ADAMETSPureMultiplicative).

To be fair, any mixed model can potentially break, when the level of series is close to zero. For example, ETS(M,A,N) can have the negative trend, which might lead to the negative level and as a result to the multiplication of pure positive error term by the negative components. Estimating such a model on real data becomes a non-trivial task. In addition, as discussed above, simulations are typically needed in order to get adequate estimates of prediction interval for models of classes 2 - 5 and conditional mean and variance for models fo classes 4 - 5. All of this in my opinion means that the more useful classification of ETS models is the following:

1. [Pure additive models](#ADAMETSPureAdditive): ANN; AAN; AAdN; ANA; AAA; AAdA;
2. [Pure multiplicative models](#ADAMETSPureMultiplicative): MNN; MMN; MMdN; MNM; MMM; MMdM;
3. Mixed models with non-multiplicative trend: MAN; MAdN; MNA; MAA; MAdA; MAM; MAdM; ANM; AAM; AAdM;
4. Mixed models with multiplicative trend: MMA; MMdA; AMN; AMdN; AMA; AMdA; AMM; AMdM;

The main idea behind the split to (3) and (4) is because the presence of multiplicative trend makes it almost impossible to derive the formulae for the conditional moments of distribution. So this class of models can be considered as the most challenging.

`adam()` function supports all 30 ETS models, but you should keep in mind the limitations of some of them discussed in this section.


## Mixed models with non-multiplicative trend {#ADAMETSMixedModelsGroup3}
In this class of models, there are two subclasses: one with non-multiplicative seasonal component (MAN, MAdN, MNA, MAA, MAdA) and another one with the multiplicative one (MAM; MAdM; ANM; AAM; AAdM). The conditional mean for the former models coincides with the point forecasts, while the conditional variance can be calculated using the following recursive formula [@Hyndman2008b]:
\begin{equation}
	\begin{aligned}
	& \text{V}(y_{t+h}|t) = (1+\sigma^2) \xi_h - \mu_{t+h|t}^2 \\
	& \text{where } \xi_{1} = \mu_{t+1|t}^2 \text{ and } \xi_h = \mu_{t+h|t}^2 + \sigma^2 \sum_{j=1}^{h-1} c_{j}^2 \xi_{h-j}
	\end{aligned} ,
	(\#eq:ETSADAMMixedModels31Variance)
\end{equation}
where $\sigma^2$ is the variance of the error term. As for the second subgroup, the conditional mean corresponds to the point forecasts, when the forecast horizon is less than or equal to the seasonal frequency of the component (i.e. $h\leq m$), and there is a cumbersome formula for calculating the conditional mean to some of models in this subgroup for the $h>m$. When it comes to the conditional variance, there exists the formula for some of models in the second subgroup, but they are cumbersome as well. The interested reader is directed to @Hyndman2008b, page 85.

When it comes to the parameters bounds for the models in this group, the first subgroup of models should have [similar bounds to the ones for the respective additive error](#stabilityConditionAdditiveError) models (because both underly the same exponential smoothing methods), but with additional restrictions, comming from [the multiplicative error](#stabilityConditionMultiplicativeError).

1. The *traditional bounds* (aka "usual") should work fine for these models for the same reasons they work for the pure additive models, although they might be too restrictive in some cases;
2. The *admissible bounds* for smoothing parameters for the models in this group might be too wide and violate the condition of $(1+ \alpha \epsilon_t)>0, (1+ \beta \epsilon_t)>0, (1+ \gamma \epsilon_t)>0$, which is important in order not to break the models.

The second subgroup is more challenging in terms of parameters bounds because of the multiplication of states by the seasonal components. 

## Mixed models with multiplicative trend {#ADAMETSMixedModelsGroup4}
This is the most difficult class of models (MMA; MMdA; AMN; AMdN; AMA; AMdA; AMM; AMdM). These do not have analytical formulae for conditional moments, they are very sensitive to the values of smoothing parameters and may lead to explosive forecasting trajectories. So, in order to obtain conditional expectation, variance and prediction interval from the models of this classs, simulations should be used.

One of the issues that can be encountered, when using these models is the explosive trajectories because of the multiplicative trend. As a result, when these models are estimated, it makes sense to set the initial value of trend to 1 or a lower value, so that the optimiser does not encounter difficulties in the calculations.

Furthermore, the combination of components for the models in this class makes even less sense than the combination for [the previous class](#ADAMETSMixedModelsGroup3) of models. For example, the multiplicative trend assumes either the explosive growth or decay as shown on the following two figures:

```{r echo=FALSE}
par(mfcol=c(1,2))
plot(exp(0.05*c(1:100)),type="l",ylab="Demand",xlab="Time")
plot(exp(-0.05*c(1:100)),type="l",ylab="Demand",xlab="Time")
```

Assuming that either seasonal component, or the error term, or both will have exactly the same impact on the final value irrespective of the point of time is unrealistic for these situation. The more reasonable would be for the amplitude of seasonality to decrease together with the exponential decay of the trend and for the variance of the error term to do the same. But this means that we are talking about the [pure multiplicative models](#ADAMETSPureMultiplicative), not the mixed ones. There is only one situation, where such mixed models could make sense: when the speed of change of the exponential trajectory is close to zero, meaning that the level of the series does not change rapidly and when the volume of the data is high. In this case the mixed models might perform well and even produce more accurate forecasts than the models from the other classes.

When it comes to the parameters bounds, this is a mistery for the mixed models. This is because the recursive relations are complicated and calculating the discount matrix or anything like that becomes a challenging task. Using the usual bounds should still be okay, but keep in mind that these mixed models are typically not very stable, so from my experience the smoothing parameters should be as low as possible, assuming that the initial values guarantee a working model (not breaking at some of observations).

