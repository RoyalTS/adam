# ADAM ARIMA {#ADAMARIMA}
Another important dynamic element in ADAM is ARIMA model [developed by @Box1976]. ARIMA stands for "AutoRegressive Integrated Moving Average", although the name does not tell much on its own and needs additional explanation. According to the idea of the model, the data might have dynamic relations over time, where the new values depend on the values on the previous observations. We will explain the main idea of ARIMA in several steps.

## Introduction to ARIMA
### AR(p) {#ADAMAR}
We start with a simple AR(1) model, which is written as:
\begin{equation}
  {y}_{t} = \phi_1 y_{t-1} + \epsilon_t ,
  (\#eq:ADAMARIMA100Example)
\end{equation}
where $\phi_1$ is the parameter of the model. This formula tells us that the value on the previous observation is carried out to the new one in the proportion of $\phi_1$. Typically, the parameter $\phi_1$ is restricted with the region (-1, 1), in order to make the model stationary, but very often in real life $\phi_1$ actually lies in (0, 1) region. The forecast trajectory of this process would typically correspond to the exponentially declining curve. Here is a simple example in R of a very basic forecast from AR(1) with $\phi_1=0.9$:
```{r}
x <- vector("numeric", 20)
x[1] <- 100
phi <- 0.9
for(i in 2:20){
    x[i] <- phi * x[i-1]
}
plot(x, type="l", xlab="horizon")
```

If for some reason we get $\phi_1>1$, then the trajectory becomes explosive, corresponding to exponential increase, implying non-stationary behaviour. The model in this case becomes very difficult to work with even if the parameters is close to one. So it is typically advised to restrict the parameter with stationarity region (we will discuss this later in this chapter).

In general, it is possible to imagine the situation, when the value at the moment of time $t$ would depend on several previous values, so the model AR(p) can be written as:
\begin{equation}
  {y}_{t} = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + \epsilon_t ,
  (\#eq:ADAMARIMAp00Example)
\end{equation}
where $\phi_i$ is the parameters for the $i$-th lag of the model. So, the model assumes that the data on the recent observations is influenced by the $p$ previous observations.

While it is difficult to come up with examples from demand forecasting context, where AR(p) model would make sense from the modelling point of view (i.e. demand does not reproduce itself, but is influenced by external factors), this model has good interpretation for physics and engineering systems. For example, @Box1976 give an example of a series of $CO_2$ output of a furnace, when the input gas rate changes. In this case, the elements of AR process are natural, as the $CO_2$ cannot just drop to zero, when the gas is switched off - it will leave the furnace, in reducing quantity over time (i.e. leaving $\phi_1\times100\%$ of $CO_2$ on the next minute). Another example, where AR processes are natural is the temperature in the room, measured with 5 minutes intervals. In this case the temperature at 5.30pm will depend on the temperature at 5.25pm (if the temperature outside the room is lower, then it will go down slightly due to the loss of heat). So, the AR(p) model can be considered as a "true model" in such context, but when it comes to time series from the social domain, it becomes very difficult to motivate the usage of the model from the general understanding of the problem. At best, AR can be considered as an approximation of a very crude true process. So, whenever we work with AR models in this domain, we should keep in mind that they are wrong even from the philosophical point of view. But they still can be useful.


### I(d)

### MA(q)
