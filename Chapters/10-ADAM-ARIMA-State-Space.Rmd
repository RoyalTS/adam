# ADAM ARIMA {#ADAMARIMA}
There are different ways to formulate and implement ARIMA. The one discussed in the [previous section](#ARIMA) is the conventional model, which can be estimate directly, assuming that the initialisation of the model happens some time before the Big Bang: the conventional ARIMA assumes that there is no starting point of the model, we just observe a specific piece of data from a population without any beginning or end. Obviously this assumption is idealistic and does not necessarily agree with reality (imagine the series of infinitely lasting sales of Siemens mobile phones).

Besides the conventional formulation, there is also a state space form of ARIMA, implemented in SSOE [@Hyndman2008b]. @Svetunkov2019 adapted this state space model for supply chain forecasting, developing an order selection mechanism, sidesteping the hypothesis testing and focusing on information criteria. However, the main issue with this approach is that the resulting ARIMA model works very slow on the data with large frequencies (because the transition matrix becomes huge). Luckily, there is an alternative SSOE state space formulation, using the same idea of lags as [ADAM ETS](#ADAMETSIntroduction). This model is already implemented in `msarima()` function of `smooth` package and was also used as the basis for the ADAM ARIMA.


## State space ARIMA {#StateSpaceARIMA}
### Additive ARIMA
In order to develop state space ARIMA, we will use the most general multiple seasonal ARIMA, discussed in [the previous section](#MSARIMA):
\begin{equation*}
  y_t \prod_{j=0}^n \Delta^{D_j} (B^{m_j}) \varphi^{P_j}(B^{m_j}) = \epsilon_t \prod_{j=0}^n \vartheta^{Q_j}(B^{m_j}) ,
\end{equation*}
This model can be represented in an easier to digest form by expanding the polynomials on the left hand side of the equation and moving all the previous values to the right hand side and then expanding the MA polynomials:
\begin{equation}
  y_t = \sum_{j=1}^K \eta_j y_{t-j} + \sum_{j=1}^K \theta_j \epsilon_{t-j} + \epsilon_t .
  (\#eq:MSARIMAExpanded)
\end{equation}
Here $K$ is the order of the highest polynomial, calculated as $K=\max\left(\sum_{j=0}^n (P_j + D_j)m_j, \sum_{j=0}^n Q_j m_j\right)$. If, for example, the MA order is higher than the sum of ARI orders, then polynomials $\eta_i=0$ for $i>\sum_{j=0}^n (P_j + D_j)m_j$. The same property holds for the opposite situation of the sum of ARI orders being higher than the MA orders. Based on this we could define states for each of the previous elements:
\begin{equation}
  v_{i,t-i} = \eta_i y_{t-i} + \theta_i \epsilon_{t-i},
  (\#eq:MSARIMAState)
\end{equation}
leading to the following model based on \@ref(eq:MSARIMAState) and \@ref(eq:MSARIMAExpanded):
\begin{equation}
  y_t = \sum_{j=1}^K v_{j,t-j} + \epsilon_t .
  (\#eq:MSARIMAMeasurement01)
\end{equation}
This can be considered as a measurement equation of the state space ARIMA. Now if we consider the previous values of $y_t$ based on \@ref(eq:MSARIMAMeasurement01), for $y_{t-i}$, it will be equal to:
\begin{equation}
  y_{t-i} = \sum_{j=1}^K v_{j,t-j-i} + \epsilon_{t-i} .
  (\#eq:MSARIMAMeasurement02)
\end{equation}
The value \@ref(eq:MSARIMAMeasurement02) can be inserted into \@ref(eq:MSARIMAState), in order to get the transition equation:
\begin{equation}
  v_{i,t-i} = \eta_i \sum_{j=1}^K v_{j,t-j-i} + (\eta_i + \theta_i) \epsilon_{t-i}.
  (\#eq:MSARIMATransition)
\end{equation}
This leads to the SSOE state space model based on \@ref(eq:MSARIMAMeasurement02) and \@ref(eq:MSARIMATransition):
\begin{equation}
  \begin{aligned}
    &{y}_{t} = \sum_{j=1}^K v_{j,t-j} + \epsilon_t \\
    &v_{i,t} = \eta_i \sum_{j=1}^K v_{j,t-j} + (\eta_i + \theta_i) \epsilon_{t} \text{ for each } i=\{1, 2, \dots, K \}
  \end{aligned},
  (\#eq:ADAMARIMAExpanded)
\end{equation}
which can be formulated in the conventional form as a [pure additive model](#ADAMETSPureAdditive):
\begin{equation*}
  \begin{aligned}
    &{y}_{t} = \mathbf{w}' \mathbf{v}_{t-\mathbf{l}} + \epsilon_t \\
    &\mathbf{v}_{t} = \mathbf{F} \mathbf{v}_{t-\mathbf{l}} + \mathbf{g} \epsilon_t
  \end{aligned},
\end{equation*}
with the following values for matrices:
\begin{equation}
  \begin{aligned}
    \mathbf{F} = \begin{pmatrix} \eta_1 & \eta_1 & \dots & \eta_1 \\ \eta_2 & \eta_2 & \dots & \eta_2 \\ \vdots & \vdots & \ddots & \vdots \\ \eta_K & \eta_K & \dots & \eta_K \end{pmatrix}, & \mathbf{w} = \begin{pmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{pmatrix}, \\
    \mathbf{g} = \begin{pmatrix} \eta_1 + \theta_1 \\ \eta_2 + \theta_2 \\ \vdots \\ \eta_K + \theta_K \end{pmatrix}, & \mathbf{v}_{t} = \begin{pmatrix} v_{1,t} \\ v_{2,t} \\ \vdots \\ v_{K,t} \end{pmatrix}, & \mathbf{l} = \begin{pmatrix} 1 \\ 2 \\ \vdots \\ K \end{pmatrix}
  \end{aligned}.
  (\#eq:ADAMARIMAMatrices)
\end{equation}
States in this model do not have any specific meaning, they just represent a combination of actual values and error terms, some portion of ARIMA model. Furthermore, there are zero states in this model, corresponding to zero polynomials of ARI and MA. These can be dropped to make the model even more compact.

### An example
In order to better understand what the state space model \@ref(eq:ADAMARIMAExpanded) implies, we consider an example of SARIMA(1,1,2)(0,1,0)$_4$:
\begin{equation*}
    {y}_{t} (1- \phi_1 B)(1-B)(1-B^4) = \epsilon_t (1 + \theta_1 B + \theta_2 B^2),
\end{equation*}
which can be rewritten in the expanded form:
\begin{equation*}
    {y}_{t} (1-\phi_1 B - B + \phi_1 B^2 - B^4 +\phi_1 B^5 + B^5 - \phi_1 B^6) = \epsilon_t (1 + \theta_1 B + \theta_2 B^2),
\end{equation*}
or after moving the previous values to the right hand side:
\begin{equation*}
    {y}_{t} = (1+\phi_1) {y}_{t-1} - \phi_1 {y}_{t-2} + {y}_{t-4} - (1+\phi_1) {y}_{t-5} + \phi_1 {y}_{t-6} + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \epsilon_t .
\end{equation*}
The polynomials in this case can be written as:
\begin{equation*}
    \begin{aligned}
    & \eta_1 = 1+\phi_1 \\
    & \eta_2 = -\phi_1 \\
    & \eta_3 = 0 \\
    & \eta_4 = 1 \\
    & \eta_5 = - (1+\phi_1) \\
    & \eta_6 = \phi_1
    \end{aligned} ,
\end{equation*}
leading to 6 states, one of which can be dropped (the third one, for which both $\eta_3=0$ and $\theta_3=0$). The state space ARIMA can then be written as:
\begin{equation*}
    \begin{aligned}
    &{y}_{t} = \sum_{j=1,2,4,5,6} v_{j,t-j} + \epsilon_t \\
    & v_{1,t} = (1+\phi_1) \sum_{j=1}^6 v_{j,t-j} + (1+\phi_1+\theta_1) \epsilon_t \\
    & v_{2,t} = -\phi_1 \sum_{j=1}^6 v_{j,t-j} + (-\phi_1+\theta_2) \epsilon_t \\
    & v_{4,t} = \sum_{j=1}^6 v_{j,t-j} + \epsilon_t \\
    & v_{5,t} = -(1+\phi_1) \sum_{j=1}^6 v_{j,t-j} -(1+\phi_1) \epsilon_t \\
    & v_{6,t} = \phi_1 \sum_{j=1}^6 v_{j,t-j} + \phi_1 \epsilon_t
    \end{aligned} .
\end{equation*}
This model looks more complicated than the original ARIMA in the conventional form, but it bring the model to the same ground as [ETS in ADAM](#ADAMETSIntroduction), making them directly comparable via information criteria and allowing to easily combine the two models, not to mention compare ARIMA of any order with another ARIMA (e.g. with different orders of differencing).

### State space ARIMA with constant
If we want to add the [constant](#ARMAConstant) to the model, we need to modify the equation \@ref(eq:MSARIMAExpanded):
\begin{equation}
  y_t = \sum_{j=1}^K \eta_j y_{t-j} + \sum_{j=1}^K \theta_j \epsilon_{t-j} + a_0 + \epsilon_t .
  (\#eq:MSARIMAExpandedConstant)
\end{equation}
This then leads to the appearance of the new state:
\begin{equation}
  v_{K+1,t} = a_0 ,
  (\#eq:MSARIMAStateConstant)
\end{equation}
which leads to the modified measurement equation:
\begin{equation}
  y_t = \sum_{j=1}^{K+1} v_{j,t-j} + \epsilon_t ,
  (\#eq:MSARIMAMeasurementConstant)
\end{equation}
and the modified transition states:
\begin{equation}
  \begin{aligned}
    & v_{i,t} = \eta_i \sum_{j=1}^{K+1} v_{j,t-j} + (\eta_i + \theta_i) \epsilon_{t} , \text{ for } i=\{1, 2, \dots, K\} \\
    & v_{K+1, t} = v_{K+1, t-1} .
  \end{aligned}
  (\#eq:MSARIMATransitionConstant)
\end{equation}
The state space equations \@ref(eq:MSARIMAMeasurementConstant) and \@ref(eq:MSARIMATransitionConstant) lead to the following matrices:
\begin{equation}
  \begin{aligned}
    \mathbf{F} = \begin{pmatrix} \eta_1 & \dots & \eta_1 & \eta_1 \\ \eta_2 & \dots & \eta_2 & \eta_2 \\ \vdots & \vdots & \ddots & \vdots \\ \eta_K & \dots & \eta_K & \eta_K \\ 0 & \dots & 0 & 1 \end{pmatrix}, & \mathbf{w} = \begin{pmatrix} 1 \\ 1 \\ \vdots \\ 1 \\ 1 \end{pmatrix}, \\
    \mathbf{g} = \begin{pmatrix} \eta_1 + \theta_1 \\ \eta_2 + \theta_2 \\ \vdots \\ \eta_K + \theta_K \\ 0 \end{pmatrix}, & \mathbf{v}_{t} = \begin{pmatrix} v_{1,t} \\ v_{2,t} \\ \vdots \\ v_{K,t} \\ v_{K+1,t} \end{pmatrix}, & \mathbf{l} = \begin{pmatrix} 1 \\ 2 \\ \vdots \\ K \\ 1 \end{pmatrix}
  \end{aligned}.
  (\#eq:ADAMARIMAMatricesConstant)
\end{equation}

Note that the constant term introduced in this model has different meaning, depending on the differences of the model. For example, if all $D_j=0$, then it acts as an intercept, while for the $d=1$, it will act as a drift. 

### Multiplicative ARIMA
In order to connect ARIMA with ETS, we also need to define cases for multiplicative models. This implies that the error term $(1+\epsilon_t)$ is multiplied by components of the model. The state space ARIMA in this case is formulated using logarithms in the following way:
\begin{equation}
  \begin{aligned}
    &{y}_{t} = \exp \left( \sum_{j=1}^K \log v_{j,t-j} + \log(1+\epsilon_t) \right) \\
    &\log v_{i,t} = \eta_i \sum_{j=1}^K \log v_{j,t-j} + (\eta_i + \theta_i) \log(1+\epsilon_t) \text{ for each } i=\{1, 2, \dots, K \}
  \end{aligned}.
  (\#eq:ADAMARIMAExpandedMultiplicative)
\end{equation}
The model \@ref(eq:ADAMARIMAExpandedMultiplicative) can be written in the following more general form:
\begin{equation}
  \begin{aligned}
    &{y}_{t} = \exp \left( \mathbf{w}' \log \mathbf{v}_{t-\mathbf{l}} + \log(1+\epsilon_t) \right) \\
    &\log \mathbf{v}_{t} = \mathbf{F} \log \mathbf{v}_{t-\mathbf{l}} + \mathbf{g} \log(1+\epsilon_t)
  \end{aligned},
  (\#eq:ADAMStateSpaceMultiplicative)
\end{equation}
where $\mathbf{w}$, $\mathbf{F}$, $\mathbf{v}_t$, $\mathbf{g}$ and $\mathbf{l}$ are defined as before for the [additive ARIMA](#StateSpaceARIMA), e.g. in equation \@ref(eq:ADAMARIMAMatricesConstant). This model is equivalent to applying ARIMA to log-transformed data, but at the same time shares some similarities with [pure multiplicative ETS](#ADAMETSPureMultiplicative). The main advantage of this formulation is that this model has analytical solutions for the conditional moments and has well defined h steps ahead distributions, which simplifies the work with it in contrast with the [pure multiplicative ETS](#ADAMETSPureMultiplicative) models.


## Parameters bounds


## Moments of ADAM ARIMA
Having formulated ARIMA in state space forms \@ref(eq:ETSADAMStateSpacePureAdditive) (pure additive) and \@ref(eq:ADAMStateSpaceMultiplicative) (pure multiplicative), we can now calculate the conditional moments for ADAM ARIMA.

In case of the pure additive ARIMA model, the moments correspond to the ones discussed in the [pure additive ETS section](#ADAMETSPureAdditive):
\begin{equation*}
  \begin{aligned}
    \mu_{y,t+h} = \mathrm{E}(y_{t+h}|t) = & \sum_{i=1}^d \left(\mathbf{w}_{m_i}' \mathbf{F}_{m_i}^{\lceil\frac{h}{m_i}\rceil-1} \right) \mathbf{v}_{t} \\
    \sigma^2_{h} = \mathrm{V}(y_{t+h}|t) = & \left( \sum_{i=1}^d \left(\mathbf{w}_{m_i}' \sum_{j=1}^{\lceil\frac{h}{m_i}\rceil-1} \mathbf{F}_{m_i}^{j-1} \mathbf{g}_{m_i} \mathbf{g}'_{m_i} (\mathbf{F}_{m_i}')^{j-1} \mathbf{w}_{m_i} \right) + 1 \right) \sigma^2
  \end{aligned},
\end{equation*}
where in our case $m_i$ corresponds to each lag in the vector $\mathbf{l}$. Another thing to note that due to how we formulated the model, each $\mathbf{w}_{m_i}$ and $\mathbf{g}_{m_i}$ would contain only one non-zero element, while the matrix $\mathbf{F}_{m_i}$ would be sparse, containing only one non-zero column $i$.

When it comes to the multiplicative ARIMA model, using the same idea with recursive relation as in the [pure additive ETS section](#adamETSPureAdditiveRecursive), we can obtain the logarithmic moments:
\begin{equation}
  \begin{aligned}
    \mu_{\log y,t+h} = \mathrm{E}(\log y_{t+h}|t) = & \sum_{i=1}^d \left(\mathbf{w}_{m_i}' \mathbf{F}_{m_i}^{\lceil\frac{h}{m_i}\rceil-1} \right) \log \mathbf{v}_{t} \\
    \sigma^2_{\log y,h} = \mathrm{V}(\log y_{t+h}|t) = & \left( \sum_{i=1}^d \left(\mathbf{w}_{m_i}' \sum_{j=1}^{\lceil\frac{h}{m_i}\rceil-1} \mathbf{F}_{m_i}^{j-1} \mathbf{g}_{m_i} \mathbf{g}'_{m_i} (\mathbf{F}_{m_i}')^{j-1} \mathbf{w}_{m_i} \right) + 1 \right) \sigma_{\log \epsilon}^2
  \end{aligned},
  (\#eq:ADAMARIMAMultiplicativeMomentsLogs)
\end{equation}
where $\sigma_{\log \epsilon}^2$ is the variance of the error term in logarithms. The obtained logarithmic moments can then be used to get the normal ones, after making assumptions about the distribution of the random variable. For example, if we assume that $\left(1+\epsilon_t \right) \sim \mathrm{log}\mathcal{N}\left(-\frac{\sigma^2}{2}, \sigma^2\right)$, then the conditional expectation and variance can be calculated as:
\begin{equation}
  \begin{aligned}
    & \mu_{y,t+h} = \mathrm{E}(y_{t+h}|t) = \exp \left(\mu_{\log y,t+h} + \frac{\sigma^2_{\log y,h}}{2} \right) \\
    & \sigma^2_{h} = \mathrm{V}(y_{t+h}|t) = \left(\exp\left( \sigma^2_{\log y,h} \right) - 1 \right)\exp\left(2 \times \mu_{\log y,t+h} + \sigma^2_{\log y,h} \right)
  \end{aligned}.
  (\#eq:ADAMARIMAMultiplicativeMomentsLogN)
\end{equation}
If some other distributions are assumed in the model, then the connection between the logarithmic and normal moments should be used in order to get the conditional expectation and variance. If these relations are not available, then simulations can be used in order to obtain the numeric approximations.


<!-- ## Distributional assumptions of ADAM ARIMA -->


<!-- ## ETS + ARIMA -->


<!-- ## Examples in R -->

