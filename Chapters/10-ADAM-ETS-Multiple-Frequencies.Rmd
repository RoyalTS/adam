# Multiple frequencies in ADAM ETS

@Taylor2003 proposed an exponential smoothing model with double seasonality and applied it to energy data. Since then, the topic was developed by @Gould2008, @Taylor2008, @Taylor2010, @DeLivera2010 and @DeLivera2011. In this chapter we will discuss some of the proposed models, how they relate to the ADAM framework and can be implemented. Roughly, the idea of a model with multiple seasonalities is in introducing additional seasonal components. For the general framework this means that the state vector (for example, in a model with trend and seasonality) becomes:
\begin{equation}
    \mathbf{v}_t' =
    \begin{pmatrix}
    l_t & b_t & s_{t,1} & s_{t,2} & \dots & s_{t,n}
    \end{pmatrix},
  (\#eq:ETSADAMSeasonalMultiStateVector)
\end{equation}
where $n$ is the number of seasonal components. The lag matrix in this case becomes:
\begin{equation}
    \mathbf{l}'=\begin{pmatrix}1 & 1 & m_1 & m_2 & \dots & m_n \end{pmatrix},
    (\#eq:ETSADAMSeasonalMultiStateVectorLags)
\end{equation}
where $m_i$ is the $i$-th seasonal periodicity. While, in theory there can be combinations between additive and multiplicative seasonal components, we argue that such a mixture does not make sense, and the components should align with each other. This means that in case of ETS(M,N,M), all seasonal components should be multiplicative, while in ETS(A,A,A) they should be additive. This results fundamentally in two types of models:

1. Additive seasonality:
\begin{equation}
  \begin{aligned}
    & {y}_{t} = \check{y}_t + s_{1,t-m_1} + \dots + s_{n,t-m_n} \epsilon_t \\
    & \vdots \\
    & s_{1,t} = s_{1,t-m_1} + \gamma_1 \epsilon_t \\
    & \vdots \\
    & s_{n,t} = s_{n,t-m_n} + \gamma_n \epsilon_t
  \end{aligned},
  (\#eq:ETSADAMAdditiveSeasonality)
\end{equation}
where $\check{y}_t$ is the point value based on all non-seasonal components (e.g. $\check{y}_t=l_{t-1}$ in case of no trend model) and $\gamma_i$ is the $i$-th seasonal smoothing parameter.

2. Multiplicative seasonality:
\begin{equation}
  \begin{aligned}
    & {y}_{t} = \check{y}_t \times s_{1,t-m_1} \times \dots \times s_{n,t-m_n} \times(1+\epsilon_t) \\
    & \vdots \\
    & s_{1,t} = s_{1,t-m_1} (1 + \gamma_1 \epsilon_t) \\
    & \vdots \\
    & s_{n,t} = s_{n,t-m_n} (1+ \gamma_n \epsilon_t)
  \end{aligned}.
  (\#eq:ETSADAMMultiplicativeSeasonality)
\end{equation}

Depending on a specific model, the number of seasonal components can be 1, 2, 3 or more (although more than 3 might not make much sense from modelling point of view). @DeLivera2010 introduced components based on fourier terms, updated over time via smoothing parameters. This feature is not yet fully supported in `adam()`, but it is possible to substitute some of seasonal components (especially those that have fractional periodicity) with fourier terms via explanatory variables and update them over time. The explanatory variables idea was discussed in the [previous chapter](#ETSX).


## Using explanatory variables for multiple seasonality
The conventional way of introducing several seasonal components has several issues:

1. It only works with the data with fixed periodicity (the problem sometimes referred to as "fractional frequency"): if $m_i$ is not fixed and changes from period to period, the model becomes disaligned. An example of such problem is fitting ETS on daily data with $m=365$, while there are leap years that contain 366 days;
2. If the model is fit on high frequency data, the problem of parameters estimation becomes non-trivial. Indeed, on daily data with $m=365$, we need to estimate 364 initial seasonal indices together with the other parameters;
3. Different seasonal indices would "compete" with each other for each observation, thus making the model overfit the data. An example is the daily data with $m_1=7$ and $m_2=365$, where both seasonal components are updated on each observation based on the same error, but with different smoothing parameters.

The situation becomes even more complicated, when the model has more than two seasonal components. But there are at least two ways of resolving these issues in ADAM framework.

The first is based on the idea of @DeLivera2010 and the [dynamic ETSX](#ETSXDynamic). In this case we need to generate fourier series and use them as explanatory variables in the model, switching on the mechanism of adaptation. For example, for the pure additive model, in this case, we will have:
\begin{equation}
  \begin{aligned}
    & {y}_{t} = \check{y}_t + \sum_{i=1}^n a_{i,t-1} x_{i,t} + \epsilon_t \\
    & \vdots \\
    & a_{i,t} = a_{i,t-1} + \delta_i \frac{\epsilon_t}{x_{i,t}} \text{ for each } i \in \{1, \dots, n\}
  \end{aligned},
  (\#eq:ETSXADAMMultipleSeasonalityFourier)
\end{equation}
where $n$ is the number of fourier harmonics. In this case, we can introduce the conventional seasonal part of the model for the fixed periodicity (e.g. days of week)in $\check{y}_t$ and use the updated harmonics for the non-fixed one. This approach is not the same as the one in @DeLivera2010, but might lead to similar results. The only issue here is in the selection of the number of harmonics, which can be done via the [variables selection mechanism](#ETSXSelection).

The second option is based on the idea of [dynamic model with categorical variables](#ETSXDynamicCategories). In this case, instead of trying to fix the problem with days of year, we first introduce the categorical variables for days of week and then for the weeks of year (or months of year if we can assume that the effects of months are more appropriate). After that we can introduce both categorical variables in the model, using the similar adaptation mechanism to \@ref(eq:ETSXADAMMultipleSeasonalityFourier). In fact, if some of variables have fixed periodicity, we can substitute them with the conventional seasonal components. So, for example, in this case, ETSX(M,N,M)[7]{D} could be written as:
\begin{equation}
  \begin{aligned}
    & {y}_{t} = l_{t-1} s_{t-7} \times \prod_{i=1}^n \exp(a_{i,t-1} x_{i,t}) (1 + \epsilon_t) \\
    & l_t = l_{t-1} (1 + \alpha\epsilon_t) \\
    & s_t = s_{t-7} (1 + \gamma\epsilon_t) \\
    & a_{i,t} = & a_{i,t-1} + \left \lbrace \begin{aligned}
                  &\delta \log(1+\epsilon_t) \text{ for each } i \in \{1, \dots, n\}, \text{ if } x_{i,t} = 1 \\
                  &0 \text{ otherwise }
            \end{aligned} \right.
  \end{aligned},
  (\#eq:ETSXADAMMultipleSeasonalityCategories)
\end{equation}
where $n$ is the number of levels in the categorical variable (for weeks of year, this should be 53). The number of parameters to estimate in this case might be greater than the number of harmonics in the first case, but this type of model resolves all three issues as well and does not have the dilema about selecting the number of harmonics.



## Normalisation of seasonal indices in ETS models
One of the ideas arrising from [time series decomposition](#ClassicalDecomposition), inheritted by the conventional ETS, is the idea of renormalisation of seasonal indices. It comes to one of the two principles, depending on the type of seasonality:

1. If the model has additive seasonality, then the seasonal indices should add up to zero in a specific period of time, e.g. monthly indices should add up to 0 over a yearly period;
2. If the model has multiplicative seasonality, then the geometric mean of seasonal indices over a specific period should be equal to one.

(2) in the conventional ETS is substituted by "the arithmetic mean of multiplicative indices should be equal to one", which does not have good grounds behind it - if we deal with multiplicative effect, then the geometric mean should be used, not the arithmetic one, otherwise by multiplying components by indices we introduce bias in the model. While the normalisation is a natural element of the time series decomposition and works fine for the initial seasonal indices, renormalising the seasonal indices over time might not be a natural idea for the ETS.

@Hyndman2008b discuss different mechanisms for the renormalisation of seasonal indices, which as the authors claim are needed in order to make the principles (1) and (2) hold from period to period in the data. However, I argue that this is an unnatural idea for the ETS models, that the indices should only be normalised during the initialisation of the model (at the moment $t=0$) and that they should vary independently for the rest of the sample. The rationale for this comes from the model itself. To illustrate it, I will use ETS(A,N,A), but the idea can be easily used for any other ETS model with any types of components and any number of seasonal frequencies. Just a reminder, the model can be formulated as:
\begin{equation}
  \begin{aligned}
  y_t = &l_{t-1} + s_{t-m} + \epsilon_t \\
  {l}_{t} = &l_{t-1} + \alpha\epsilon_t \\
  s_t = &s_{t-m} + \gamma\epsilon_t
  \end{aligned}.
  (\#eq:ETSANAExampleNormalisation)
\end{equation}
Let's assume that this is the true model for whatever data we have for whatever reasons. In this case the set of equations \@ref(eq:ETSANAExampleNormalisation) tells us that the seasonal indices change over time, depending on the values of the smoothing parameter $\gamma$ and each specific values of $\epsilon_t$, which is assumed to be i.i.d. All seasonal indeces $s_{t+i}$ in a specific period (e.g. monthly indices in a year) can be written down explicitly based on \@ref(eq:ETSANAExampleNormalisation):
\begin{equation}
  \begin{aligned}
  s_{t+1} = &s_{t+1-m} + \gamma\epsilon_{t+1} \\
  s_{t+2} = &s_{t+2-m} + \gamma\epsilon_{t+2} \\
  \vdots \\
  s_{t+m} = &s_{t} + \gamma\epsilon_{t+m}
  \end{aligned}.
  (\#eq:ETSANAExampleNormalisationIndices01)
\end{equation}
If this is how the data is "generated" and the seasonality evolves over time, then there is only one possibility, for the indices $s_{t+1}, s_{t+2}, \dots, s_{t+m}$ to add up to zero:
\begin{equation}
  \begin{aligned}
  &s_{t+1}+ s_{t+2}+ \dots+ s_{t+m} = 0 \\
  &s_{t+1-m}+ s_{t+2-m}+ \dots+ s_{t} + \gamma \left(\epsilon_{t+1}+ \epsilon_{t+2}+ \dots+ \epsilon_{t+m}\right) = 0
  \end{aligned}.
  (\#eq:ETSANAExampleNormalisationIndices02)
\end{equation}
meaning that:

a. the previous indices $s_{t+1-m}, s_{t+2-m}, \dots, s_{t}$ add up to zero **and**
b. either $\gamma=0$,
c. or the sum of error terms $\epsilon_{t+1}, \epsilon_{t+2}, \dots, \epsilon_{t+m}$ is zero.

Note that we do not consider the situation $s_{t+1-m}+ \dots+ s_{t} = - \gamma \left(\epsilon_{t+1}+ \dots+ \epsilon_{t+m}\right)$ as it does not make sense. The condition (a) can be considered reasonable if the previous indices are normalised. (b) means that the seasonal indices do not evolve over time. However, (c) implies that the error term is not independent, because $\epsilon_{t+m} = -\epsilon_{t+1}- \epsilon_{t+2}- \dots- \epsilon_{t+m-1}$, which violates one of the [basic assumptions](#assumptions) of the model, meaning that \@ref(eq:ETSANAExampleNormalisation02) cannot be considered as the "true" model anymore, as it omits some important elements.

The other case, when each seasonal index is updated on each observation $t$ (to make sure that the indices are normalised), does not make sense either. In this situation we have:
\begin{equation}
  \begin{aligned}
  &s_t = s_{t-m} + \gamma\epsilon_t \\
  &s_{t-m+1}+ s_{t-m+2}+ \dots+ s_{t-1} + s_{t} = 0
  \end{aligned},
  (\#eq:ETSANAExampleNormalisationIndices03)
\end{equation}
which can be rewritten as $s_{t-m} + \gamma\epsilon_t = -s_{t+1-m}- s_{t+2-m}- \dots- s_{t-1}$, meaning that:
\begin{equation}
  \begin{aligned}
  s_{t-m}+ s_{t+1-m}+ s_{t+2-m}+ \dots+ s_{t-1} = -\gamma\epsilon_t
  \end{aligned},
  (\#eq:ETSANAExampleNormalisationIndices03)
\end{equation}
but due to the normalisation, the sum on the left hand side should be equal to zero, implying that either $\gamma=0$ or $\epsilon_t=0$. While former might hold in some cases (deterministic seasonality), the latter cannot hold for all $t=1,\dots,T$ and violates the assumptions of the model.

The discussion in this section demonstrate that the renormalisation of seasonal indices is unnatural for the ETS model and should not be used. Having said that, this does not imply that the initial seasonal indices (those that correspond to the observation $t=0$) cannot be normalised. In fact, the normalisation of the initial indices allows reducing the number of estimated parameters in the model.
